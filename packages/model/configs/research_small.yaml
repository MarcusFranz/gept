# Research configuration for small-scale experiments
# Optimized for 3060/MacBook with 32GB RAM

data:
  recent_hours: 24        # 5-min resolution, 288 timesteps
  medium_days: 7          # 1-hour resolution, 168 timesteps
  long_days: 30           # 4-hour resolution, 180 timesteps
  max_gap_pct: 0.05       # Max 5% missing data
  outlier_threshold: 0.5  # Flag >50% price changes

model:
  # Multi-resolution input dimensions
  recent_len: 288         # 24h at 5-min
  recent_features: 6
  medium_len: 168         # 7d at 1-hour
  medium_features: 10
  long_len: 180           # 30d at 4-hour
  long_features: 10

  # Transformer architecture
  patch_size: 16
  d_model: 384
  n_heads: 8
  n_layers: 6
  d_ff: 768
  dropout: 0.1

  # Quantile prediction
  n_horizons: 7           # 1h, 2h, 4h, 8h, 12h, 24h, 48h
  n_quantiles: 5          # p10, p30, p50, p70, p90

  # Item embeddings
  n_items: 500
  item_embed_dim: 32

training:
  batch_size: 256         # Fits in 8GB VRAM
  epochs: 50
  lr: 0.0001
  warmup_steps: 1000
  weight_decay: 0.01
  num_workers: 4
  checkpoint_every: 5     # Save every 5 epochs

output_dir: data
model_dir: models/patchtst_v1
